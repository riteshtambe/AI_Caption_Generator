# import streamlit as st
# from PIL import Image
# from utils import generate_blip2_captions, rank_with_clip, generate_speech
# import base64

# st.set_page_config(page_title="ğŸ–¼ï¸ Accurate AI Caption Narrator", layout="centered")
# st.title("ğŸ–¼ï¸ Image Caption Generator + ğŸ™ï¸ Voice Narrator (with BLIP-2 + CLIP)")

# st.markdown("This app generates **highly accurate image captions** and narrates them with natural voice.")

# uploaded_file = st.file_uploader("ğŸ“¤ Upload an image", type=["jpg", "jpeg", "png"])

# if uploaded_file:
#     st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)

#     with st.spinner("ğŸ¤– Generating multiple captions with BLIP-2..."):
#         image = Image.open(uploaded_file)
#         captions = generate_blip2_captions(image, num_captions=4)

#     with st.spinner("ğŸ§  Ranking captions using CLIP..."):
#         best_caption = rank_with_clip(image, captions)

#     st.success("âœ… Most Accurate Caption Generated")
#     st.markdown(f"**ğŸ“œ Caption:** {best_caption}")

#     with st.spinner("ğŸ”Š Synthesizing voice..."):
#         audio_path = generate_speech(best_caption)

#     # ğŸ”Š Auto-play voice using base64
#     with open(audio_path, "rb") as audio_file:
#         audio_bytes = audio_file.read()
#         encoded_audio = base64.b64encode(audio_bytes).decode()

#     st.markdown(f"""
#         <audio autoplay controls>
#             <source src="data:audio/wav;base64,{encoded_audio}" type="audio/wav">
#         </audio>
#     """, unsafe_allow_html=True)

import streamlit as st
from PIL import Image
from utils import (
    generate_blip2_captions,
    rank_with_clip,
    refine_caption_with_gemini,
    translate_caption_with_gemini,
    generate_speech
)
import base64

st.set_page_config(page_title="ğŸ™ï¸ AI Image Caption Narrator", layout="centered")
st.title("ğŸ–¼ï¸ AI Image Caption Generator + ğŸ™ï¸ Voice Narrator")

st.markdown("""
This app generates a **detailed image caption** using BLIP-2, improves it with **Google Gemini**, and narrates it with **ESPnet TTS**.  
Optionally, it can also **translate** your caption.
""")

uploaded_file = st.file_uploader("ğŸ“¤ Upload an Image", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="ğŸ“· Uploaded Image", use_column_width=True)

    with st.spinner("ğŸ¤– Generating captions..."):
        captions = generate_blip2_captions(image)

    with st.spinner("ğŸ” Ranking with CLIP..."):
        best_caption = rank_with_clip(image, captions)
    st.markdown(f"**ğŸ¯ CLIP Selected Caption:** {best_caption}")

    with st.spinner("âœ¨ Enhancing with Gemini..."):
        improved_caption = refine_caption_with_gemini(best_caption)
    st.success("âœ… Caption Refined by Gemini")
    st.markdown(f"**ğŸ“œ Final Caption:** {improved_caption}")

    if st.checkbox("ğŸŒ Translate to Hindi"):
        with st.spinner("ğŸŒ Translating with Gemini..."):
            translation = translate_caption_with_gemini(improved_caption, target_language="Hindi")
        st.markdown(f"**ğŸˆ³ Hindi Translation:** {translation}")

    with st.spinner("ğŸ”Š Generating Speech..."):
        audio_path = generate_speech(improved_caption)
        with open(audio_path, "rb") as audio_file:
            audio_bytes = audio_file.read()
            encoded_audio = base64.b64encode(audio_bytes).decode()
        st.markdown(f"""
        <audio autoplay controls>
            <source src="data:audio/wav;base64,{encoded_audio}" type="audio/wav">
        </audio>
        """, unsafe_allow_html=True)
    